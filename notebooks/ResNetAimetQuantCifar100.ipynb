{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db071d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93434be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:31,055 - root - INFO - AIMET\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import ResNet\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from aimet_torch.model_preparer import prepare_model\n",
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_torch.quantsim import QuantizationSimModel, QuantParams\n",
    "from aimet_torch.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "from aimet_torch.cross_layer_equalization import equalize_model\n",
    "from aimet_torch.bias_correction import correct_bias\n",
    "\n",
    "from source.data import get_training_dataloader, get_test_dataloader\n",
    "from source.models import BasicBlock, ResNet18Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f178193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b350721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, dataloader, device='gpu'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0.0\n",
    "        for (images, labels) in tqdm(dataloader):\n",
    "            if device == 'gpu':\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum()\n",
    "\n",
    "    print('Acc:', correct.float() / len(dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114b229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf112433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_training_dataloader(\n",
    "    '../data',\n",
    "    CIFAR100_TRAIN_MEAN,\n",
    "    CIFAR100_TRAIN_STD,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = get_test_dataloader(\n",
    "    '../data',\n",
    "    CIFAR100_TRAIN_MEAN,\n",
    "    CIFAR100_TRAIN_STD,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca763c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(sim_model, device):\n",
    "    batch_size = train_loader.batch_size\n",
    "\n",
    "    sim_model.eval()\n",
    "    samples = 1000\n",
    "\n",
    "    batch_cntr = 0\n",
    "    with torch.no_grad():\n",
    "        for input_data, target_data in train_loader:\n",
    "\n",
    "            inputs_batch = input_data.to(device)\n",
    "            sim_model(inputs_batch)\n",
    "\n",
    "            batch_cntr += 1\n",
    "            print(batch_cntr * batch_size)\n",
    "            if (batch_cntr * batch_size) > samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b94cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(num_classes=100, block=BasicBlock, layers=[2, 2, 2, 2])\n",
    "model.load_state_dict(torch.load('../models/resnet18_cifar100.sd', map_location=torch.device(device)))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f04234",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8dc65",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89db89d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:53:18,450 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2022-12-21 23:53:18,450 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2022-12-21 23:53:18,451 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2022-12-21 23:53:18,452 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2022-12-21 23:53:18,452 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2022-12-21 23:53:18,453 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2022-12-21 23:53:18,453 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2022-12-21 23:53:18,454 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2022-12-21 23:53:18,454 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2022-12-21 23:53:18,455 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2022-12-21 23:53:18,455 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2022-12-21 23:53:18,456 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2022-12-21 23:53:18,457 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2022-12-21 23:53:18,457 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2022-12-21 23:53:18,458 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2022-12-21 23:53:18,458 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980bcea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:53:19,001 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2022-12-21 23:53:19,002 - Utils - INFO - ...... subset to store [Conv_4, BatchNormalization_5]\n",
      "2022-12-21 23:53:19,002 - Utils - INFO - ...... subset to store [Conv_7, BatchNormalization_8]\n",
      "2022-12-21 23:53:19,002 - Utils - INFO - ...... subset to store [Conv_11, BatchNormalization_12]\n",
      "2022-12-21 23:53:19,003 - Utils - INFO - ...... subset to store [Conv_14, BatchNormalization_15]\n",
      "2022-12-21 23:53:19,003 - Utils - INFO - ...... subset to store [Conv_18, BatchNormalization_19]\n",
      "2022-12-21 23:53:19,004 - Utils - INFO - ...... subset to store [Conv_21, BatchNormalization_22]\n",
      "2022-12-21 23:53:19,004 - Utils - INFO - ...... subset to store [Conv_27, BatchNormalization_28]\n",
      "2022-12-21 23:53:19,004 - Utils - INFO - ...... subset to store [Conv_30, BatchNormalization_31]\n",
      "2022-12-21 23:53:19,005 - Utils - INFO - ...... subset to store [Conv_34, BatchNormalization_35]\n",
      "2022-12-21 23:53:19,005 - Utils - INFO - ...... subset to store [Conv_37, BatchNormalization_38]\n",
      "2022-12-21 23:53:19,006 - Utils - INFO - ...... subset to store [Conv_43, BatchNormalization_44]\n",
      "2022-12-21 23:53:19,006 - Utils - INFO - ...... subset to store [Conv_46, BatchNormalization_47]\n",
      "2022-12-21 23:53:19,006 - Utils - INFO - ...... subset to store [Conv_50, BatchNormalization_51]\n",
      "2022-12-21 23:53:19,007 - Utils - INFO - ...... subset to store [Conv_53, BatchNormalization_54]\n",
      "2022-12-21 23:53:19,007 - Utils - INFO - ...... subset to store [Conv_59, BatchNormalization_60]\n",
      "2022-12-21 23:53:19,008 - Utils - INFO - ...... subset to store [Conv_62, BatchNormalization_63]\n",
      "2022-12-21 23:53:19,008 - Utils - INFO - ...... subset to store [Conv_55, BatchNormalization_56]\n",
      "2022-12-21 23:53:19,009 - Utils - INFO - ...... subset to store [Conv_39, BatchNormalization_40]\n",
      "2022-12-21 23:53:19,009 - Utils - INFO - ...... subset to store [Conv_23, BatchNormalization_24]\n"
     ]
    }
   ],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe3117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:53:22,829 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2022-12-21 23:53:22,849 - Quant - INFO - Unsupported op type Squeeze\n",
      "2022-12-21 23:53:22,849 - Quant - INFO - Unsupported op type Pad\n",
      "2022-12-21 23:53:22,849 - Quant - INFO - Unsupported op type Mean\n",
      "2022-12-21 23:53:22,852 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-21 23:53:22,853 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-21 23:53:22,853 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-21 23:53:22,854 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-21 23:53:22,854 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-21 23:53:22,855 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-21 23:53:22,855 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-21 23:53:22,855 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-21 23:53:22,856 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-21 23:53:22,856 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-21 23:53:22,857 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-21 23:53:22,857 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-21 23:53:22,857 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-21 23:53:22,858 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-21 23:53:22,858 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-21 23:53:22,859 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-21 23:53:22,859 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-21 23:53:22,859 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-21 23:53:22,860 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-21 23:53:22,860 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-21 23:53:22,861 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-21 23:53:22,861 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-21 23:53:22,861 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-21 23:53:22,862 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-21 23:53:22,862 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-21 23:53:22,863 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-21 23:53:22,863 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-21 23:53:22,864 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-21 23:53:22,864 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-21 23:53:22,864 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-21 23:53:22,865 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-21 23:53:22,865 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-21 23:53:22,866 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2022-12-21 23:53:22,866 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)    # Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=4,\n",
    "                           default_param_bw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92fa3590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04ceaf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 55.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.2235, device='cuda:0')\n",
      "CPU times: user 1.89 s, sys: 259 ms, total: 2.15 s\n",
      "Wall time: 2.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(sim.model, test_loader, device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3985f",
   "metadata": {},
   "source": [
    "# AdaRound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5e549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:54:11,038 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2022-12-21 23:54:11,039 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2022-12-21 23:54:11,039 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2022-12-21 23:54:11,041 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2022-12-21 23:54:11,042 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2022-12-21 23:54:11,042 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2022-12-21 23:54:11,044 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2022-12-21 23:54:11,045 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2022-12-21 23:54:11,045 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2022-12-21 23:54:11,046 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2022-12-21 23:54:11,046 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2022-12-21 23:54:11,047 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2022-12-21 23:54:11,048 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2022-12-21 23:54:11,048 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2022-12-21 23:54:11,049 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2022-12-21 23:54:11,049 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589abdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd20314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AdaroundParameters(data_loader=train_loader, \n",
    "                            num_batches=2000//train_loader.batch_size, \n",
    "                            default_num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72bec81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./cifar100_w4/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21111453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n",
      "2023-01-06 16:19:36,456 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-06 16:19:36,482 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-06 16:19:36,483 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-06 16:19:36,483 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-06 16:19:36,489 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 16:19:36,490 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 16:19:36,491 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 16:19:36,493 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 16:19:36,495 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 16:19:36,496 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 16:19:36,497 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 16:19:36,499 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 16:19:36,500 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 16:19:36,501 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 16:19:36,502 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 16:19:36,503 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 16:19:36,505 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 16:19:36,508 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 16:19:36,509 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 16:19:36,511 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 16:19:36,512 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 16:19:36,514 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 16:19:36,515 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 16:19:36,518 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 16:19:36,522 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 16:19:36,524 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 16:19:36,525 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 16:19:36,529 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 16:19:36,530 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 16:19:36,531 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 16:19:36,532 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 16:19:36,533 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 16:19:36,534 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 16:19:36,536 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 16:19:36,540 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 16:19:36,541 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 16:19:36,542 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2023-01-06 16:19:36,545 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2023-01-06 16:19:39,817 - Utils - INFO - Caching 31 batches from data loader at path location: /tmp/adaround/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:19:41,037 - Quant - INFO - Started Optimizing weight rounding of module: conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:21:19,862 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:22:47,419 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:24:16,454 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:25:58,798 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:27:41,623 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:29:34,728 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:32:04,699 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:33:13,959 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:35:54,293 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:38:36,065 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:42:20,217 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:49:03,751 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:50:30,655 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:57:30,810 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 17:04:47,316 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 17:17:34,492 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 17:42:15,588 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 17:44:38,886 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 18:09:53,089 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████▉        | 60/68 [1:50:12<35:20, 265.07s/it]"
     ]
    }
   ],
   "source": [
    "%time\n",
    "dummy_input = torch.rand(1, 3, 224, 224).to(device)\n",
    "\n",
    "ada_model = Adaround.apply_adaround(model, dummy_input, params,\n",
    "                                    path=\"cifar100_w4\", \n",
    "                                    filename_prefix='adaround', \n",
    "                                    default_param_bw=4,\n",
    "                                    default_quant_scheme=QuantScheme.post_training_tf_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c525d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8d3d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:01:17,018 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2022-12-22 00:01:17,035 - Quant - INFO - Unsupported op type Squeeze\n",
      "2022-12-22 00:01:17,036 - Quant - INFO - Unsupported op type Pad\n",
      "2022-12-22 00:01:17,036 - Quant - INFO - Unsupported op type Mean\n",
      "2022-12-22 00:01:17,039 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-22 00:01:17,040 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-22 00:01:17,040 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-22 00:01:17,041 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-22 00:01:17,041 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-22 00:01:17,042 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-22 00:01:17,042 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-22 00:01:17,042 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-22 00:01:17,043 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-22 00:01:17,043 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-22 00:01:17,044 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-22 00:01:17,044 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-22 00:01:17,044 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-22 00:01:17,045 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-22 00:01:17,045 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-22 00:01:17,046 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-22 00:01:17,046 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-22 00:01:17,046 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-22 00:01:17,047 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-22 00:01:17,047 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-22 00:01:17,048 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-22 00:01:17,048 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-22 00:01:17,049 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-22 00:01:17,049 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-22 00:01:17,049 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-22 00:01:17,050 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-22 00:01:17,050 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-22 00:01:17,051 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-22 00:01:17,051 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-22 00:01:17,051 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-22 00:01:17,052 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-22 00:01:17,052 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-22 00:01:17,053 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2022-12-22 00:01:17,053 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "dummy_input = dummy_input.to(device)\n",
    "\n",
    "sim = QuantizationSimModel(model=ada_model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=4,\n",
    "                           default_param_bw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa25e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:01:17,181 - Quant - INFO - Setting quantization encodings for parameter: conv1.weight\n",
      "2022-12-22 00:01:17,181 - Quant - INFO - Freezing quantization encodings for parameter: conv1.weight\n",
      "2022-12-22 00:01:17,182 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.weight\n",
      "2022-12-22 00:01:17,182 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.weight\n",
      "2022-12-22 00:01:17,183 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.weight\n",
      "2022-12-22 00:01:17,183 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.weight\n",
      "2022-12-22 00:01:17,184 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.weight\n",
      "2022-12-22 00:01:17,184 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.weight\n",
      "2022-12-22 00:01:17,184 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.weight\n",
      "2022-12-22 00:01:17,185 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.weight\n",
      "2022-12-22 00:01:17,185 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.weight\n",
      "2022-12-22 00:01:17,186 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.weight\n",
      "2022-12-22 00:01:17,186 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.weight\n",
      "2022-12-22 00:01:17,186 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.weight\n",
      "2022-12-22 00:01:17,187 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,187 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,188 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.weight\n",
      "2022-12-22 00:01:17,188 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.weight\n",
      "2022-12-22 00:01:17,188 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.weight\n",
      "2022-12-22 00:01:17,189 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.weight\n",
      "2022-12-22 00:01:17,189 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.weight\n",
      "2022-12-22 00:01:17,190 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.weight\n",
      "2022-12-22 00:01:17,190 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.weight\n",
      "2022-12-22 00:01:17,190 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.weight\n",
      "2022-12-22 00:01:17,191 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,191 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,192 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.weight\n",
      "2022-12-22 00:01:17,192 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.weight\n",
      "2022-12-22 00:01:17,193 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.weight\n",
      "2022-12-22 00:01:17,193 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.weight\n",
      "2022-12-22 00:01:17,193 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.weight\n",
      "2022-12-22 00:01:17,194 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.weight\n",
      "2022-12-22 00:01:17,194 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.weight\n",
      "2022-12-22 00:01:17,195 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.weight\n",
      "2022-12-22 00:01:17,195 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,195 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,196 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.weight\n",
      "2022-12-22 00:01:17,196 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.weight\n",
      "2022-12-22 00:01:17,197 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.weight\n",
      "2022-12-22 00:01:17,197 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.weight\n",
      "2022-12-22 00:01:17,197 - Quant - INFO - Setting quantization encodings for parameter: fc.weight\n",
      "2022-12-22 00:01:17,198 - Quant - INFO - Freezing quantization encodings for parameter: fc.weight\n"
     ]
    }
   ],
   "source": [
    "sim.set_and_freeze_param_encodings(encoding_path=os.path.join(\"cifar100_w4\", 'adaround.encodings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a06e320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d21d6df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 56.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.4052, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy(sim.model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60896898",
   "metadata": {},
   "source": [
    "# Cross-Layer Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a671639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:41,948 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2023-01-06 16:18:41,951 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2023-01-06 16:18:41,953 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2023-01-06 16:18:41,955 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2023-01-06 16:18:41,956 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2023-01-06 16:18:41,957 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2023-01-06 16:18:41,958 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2023-01-06 16:18:41,959 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2023-01-06 16:18:41,960 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2023-01-06 16:18:41,967 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2023-01-06 16:18:41,971 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2023-01-06 16:18:41,972 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2023-01-06 16:18:41,974 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2023-01-06 16:18:41,975 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2023-01-06 16:18:41,976 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2023-01-06 16:18:41,978 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302e3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:18:45,310 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2023-01-06 16:18:45,313 - Utils - INFO - ...... subset to store [Conv_4, BatchNormalization_5]\n",
      "2023-01-06 16:18:45,316 - Utils - INFO - ...... subset to store [Conv_7, BatchNormalization_8]\n",
      "2023-01-06 16:18:45,318 - Utils - INFO - ...... subset to store [Conv_11, BatchNormalization_12]\n",
      "2023-01-06 16:18:45,320 - Utils - INFO - ...... subset to store [Conv_14, BatchNormalization_15]\n",
      "2023-01-06 16:18:45,321 - Utils - INFO - ...... subset to store [Conv_18, BatchNormalization_19]\n",
      "2023-01-06 16:18:45,322 - Utils - INFO - ...... subset to store [Conv_21, BatchNormalization_22]\n",
      "2023-01-06 16:18:45,323 - Utils - INFO - ...... subset to store [Conv_27, BatchNormalization_28]\n",
      "2023-01-06 16:18:45,323 - Utils - INFO - ...... subset to store [Conv_30, BatchNormalization_31]\n",
      "2023-01-06 16:18:45,324 - Utils - INFO - ...... subset to store [Conv_34, BatchNormalization_35]\n",
      "2023-01-06 16:18:45,325 - Utils - INFO - ...... subset to store [Conv_37, BatchNormalization_38]\n",
      "2023-01-06 16:18:45,329 - Utils - INFO - ...... subset to store [Conv_43, BatchNormalization_44]\n",
      "2023-01-06 16:18:45,331 - Utils - INFO - ...... subset to store [Conv_46, BatchNormalization_47]\n",
      "2023-01-06 16:18:45,333 - Utils - INFO - ...... subset to store [Conv_50, BatchNormalization_51]\n",
      "2023-01-06 16:18:45,335 - Utils - INFO - ...... subset to store [Conv_53, BatchNormalization_54]\n",
      "2023-01-06 16:18:45,338 - Utils - INFO - ...... subset to store [Conv_59, BatchNormalization_60]\n",
      "2023-01-06 16:18:45,339 - Utils - INFO - ...... subset to store [Conv_62, BatchNormalization_63]\n",
      "2023-01-06 16:18:45,341 - Utils - INFO - ...... subset to store [Conv_55, BatchNormalization_56]\n",
      "2023-01-06 16:18:45,345 - Utils - INFO - ...... subset to store [Conv_39, BatchNormalization_40]\n",
      "2023-01-06 16:18:45,348 - Utils - INFO - ...... subset to store [Conv_23, BatchNormalization_24]\n"
     ]
    }
   ],
   "source": [
    "# not using batchnorm fold because of equalization\n",
    "# Note: Interestingly, CLE needs BN statistics for its procedure. \n",
    "# If a BN folded model is provided, CLE will run the CLS (cross-layer scaling) optimization step \n",
    "# but will skip the HBA (high-bias absorption) step. \n",
    "equalize_model(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a940cc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 14:55:34,980 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-06 14:55:35,208 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-06 14:55:35,209 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-06 14:55:35,210 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-06 14:55:35,220 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 14:55:35,222 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 14:55:35,229 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 14:55:35,230 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 14:55:35,231 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 14:55:35,232 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 14:55:35,233 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 14:55:35,234 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 14:55:35,235 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 14:55:35,236 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 14:55:35,237 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 14:55:35,244 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 14:55:35,252 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 14:55:35,253 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 14:55:35,254 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 14:55:35,256 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 14:55:35,258 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 14:55:35,259 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 14:55:35,265 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 14:55:35,267 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 14:55:35,268 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 14:55:35,269 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 14:55:35,270 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 14:55:35,271 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 14:55:35,273 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 14:55:35,275 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 14:55:35,276 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 14:55:35,277 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 14:55:35,279 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 14:55:35,280 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 14:55:35,284 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 14:55:35,285 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 14:55:35,286 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2023-01-06 14:55:35,287 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)  \n",
    "dummy_input = dummy_input.to(device)\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=4,\n",
    "                           default_param_bw=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c47deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b81eb73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 157/157 [02:03<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.4113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy(sim.model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25889e",
   "metadata": {},
   "source": [
    "# Bias Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f23c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias correction is applied to an equalized model\n",
    "bc_params = QuantParams(weight_bw=4, act_bw=4, round_mode=\"nearest\",\n",
    "                        quant_scheme=QuantScheme.post_training_tf_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a018fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:10:24,724 - Utils - INFO - ...... subset to store [Conv_0]\n",
      "2023-01-06 16:10:24,725 - Utils - INFO - ...... subset to store [Conv_0]\n",
      "2023-01-06 16:10:24,726 - Utils - INFO - ...... subset to store [Conv_0]\n",
      "2023-01-06 16:10:24,727 - Utils - INFO - ...... subset to store [Conv_3]\n",
      "2023-01-06 16:10:24,727 - Utils - INFO - ...... subset to store [Conv_3]\n",
      "2023-01-06 16:10:24,728 - Utils - INFO - ...... subset to store [Conv_3]\n",
      "2023-01-06 16:10:24,728 - Utils - INFO - ...... subset to store [Conv_5]\n",
      "2023-01-06 16:10:24,729 - Utils - INFO - ...... subset to store [Conv_5]\n",
      "2023-01-06 16:10:24,730 - Utils - INFO - ...... subset to store [Conv_5]\n",
      "2023-01-06 16:10:24,733 - Utils - INFO - ...... subset to store [Conv_8]\n",
      "2023-01-06 16:10:24,735 - Utils - INFO - ...... subset to store [Conv_8]\n",
      "2023-01-06 16:10:24,737 - Utils - INFO - ...... subset to store [Conv_8]\n",
      "2023-01-06 16:10:24,739 - Utils - INFO - ...... subset to store [Conv_10]\n",
      "2023-01-06 16:10:24,740 - Utils - INFO - ...... subset to store [Conv_10]\n",
      "2023-01-06 16:10:24,741 - Utils - INFO - ...... subset to store [Conv_10]\n",
      "2023-01-06 16:10:24,742 - Utils - INFO - ...... subset to store [Conv_13]\n",
      "2023-01-06 16:10:24,743 - Utils - INFO - ...... subset to store [Conv_13]\n",
      "2023-01-06 16:10:24,744 - Utils - INFO - ...... subset to store [Conv_13]\n",
      "2023-01-06 16:10:24,745 - Utils - INFO - ...... subset to store [Conv_15]\n",
      "2023-01-06 16:10:24,746 - Utils - INFO - ...... subset to store [Conv_15]\n",
      "2023-01-06 16:10:24,755 - Utils - INFO - ...... subset to store [Conv_15]\n",
      "2023-01-06 16:10:24,757 - Utils - INFO - ...... subset to store [Conv_19]\n",
      "2023-01-06 16:10:24,758 - Utils - INFO - ...... subset to store [Conv_19]\n",
      "2023-01-06 16:10:24,759 - Utils - INFO - ...... subset to store [Conv_19]\n",
      "2023-01-06 16:10:24,762 - Utils - INFO - ...... subset to store [Conv_21]\n",
      "2023-01-06 16:10:24,763 - Utils - INFO - ...... subset to store [Conv_21]\n",
      "2023-01-06 16:10:24,767 - Utils - INFO - ...... subset to store [Conv_21]\n",
      "2023-01-06 16:10:24,768 - Utils - INFO - ...... subset to store [Conv_24]\n",
      "2023-01-06 16:10:24,769 - Utils - INFO - ...... subset to store [Conv_24]\n",
      "2023-01-06 16:10:24,770 - Utils - INFO - ...... subset to store [Conv_24]\n",
      "2023-01-06 16:10:24,771 - Utils - INFO - ...... subset to store [Conv_26]\n",
      "2023-01-06 16:10:24,772 - Utils - INFO - ...... subset to store [Conv_26]\n",
      "2023-01-06 16:10:24,773 - Utils - INFO - ...... subset to store [Conv_26]\n",
      "2023-01-06 16:10:24,773 - Utils - INFO - ...... subset to store [Conv_30]\n",
      "2023-01-06 16:10:24,774 - Utils - INFO - ...... subset to store [Conv_30]\n",
      "2023-01-06 16:10:24,775 - Utils - INFO - ...... subset to store [Conv_30]\n",
      "2023-01-06 16:10:24,777 - Utils - INFO - ...... subset to store [Conv_32]\n",
      "2023-01-06 16:10:24,778 - Utils - INFO - ...... subset to store [Conv_32]\n",
      "2023-01-06 16:10:24,779 - Utils - INFO - ...... subset to store [Conv_32]\n",
      "2023-01-06 16:10:24,780 - Utils - INFO - ...... subset to store [Conv_35]\n",
      "2023-01-06 16:10:24,781 - Utils - INFO - ...... subset to store [Conv_35]\n",
      "2023-01-06 16:10:24,782 - Utils - INFO - ...... subset to store [Conv_35]\n",
      "2023-01-06 16:10:24,783 - Utils - INFO - ...... subset to store [Conv_37]\n",
      "2023-01-06 16:10:24,785 - Utils - INFO - ...... subset to store [Conv_37]\n",
      "2023-01-06 16:10:24,786 - Utils - INFO - ...... subset to store [Conv_37]\n",
      "2023-01-06 16:10:24,787 - Utils - INFO - ...... subset to store [Conv_41]\n",
      "2023-01-06 16:10:24,788 - Utils - INFO - ...... subset to store [Conv_41]\n",
      "2023-01-06 16:10:24,790 - Utils - INFO - ...... subset to store [Conv_41]\n",
      "2023-01-06 16:10:24,794 - Utils - INFO - ...... subset to store [Conv_43]\n",
      "2023-01-06 16:10:24,796 - Utils - INFO - ...... subset to store [Conv_43]\n",
      "2023-01-06 16:10:24,797 - Utils - INFO - ...... subset to store [Conv_43]\n",
      "2023-01-06 16:10:24,799 - Utils - INFO - ...... subset to store [Gemm_48]\n",
      "2023-01-06 16:10:24,803 - Utils - INFO - ...... subset to store [Conv_38]\n",
      "2023-01-06 16:10:24,805 - Utils - INFO - ...... subset to store [Conv_27]\n",
      "2023-01-06 16:10:24,806 - Utils - INFO - ...... subset to store [Conv_16]\n",
      "2023-01-06 16:10:25,185 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-06 16:10:25,209 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-06 16:10:25,211 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-06 16:10:25,211 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-06 16:10:25,216 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 16:10:25,217 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 16:10:25,217 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 16:10:25,218 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 16:10:25,218 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 16:10:25,219 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 16:10:25,220 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 16:10:25,221 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 16:10:25,222 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 16:10:25,223 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 16:10:25,223 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 16:10:25,226 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 16:10:25,226 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 16:10:25,229 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 16:10:25,230 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 16:10:25,231 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 16:10:25,234 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 16:10:25,236 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 16:10:25,238 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 16:10:25,238 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 16:10:25,240 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 16:10:25,241 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 16:10:25,242 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 16:10:25,243 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 16:10:25,245 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 16:10:25,246 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 16:10:25,246 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 16:10:25,247 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 16:10:25,248 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 16:10:25,248 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 16:10:25,249 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 16:10:25,250 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 16:10:25,251 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2023-01-06 16:10:25,251 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2023-01-06 16:10:30,568 - Quant - INFO - Correcting layer conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:10:34,022 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:10:34,025 - Quant - INFO - Correcting layer layer1.0.conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:10:39,634 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:10:39,636 - Quant - INFO - Correcting layer layer1.0.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:10:45,847 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:10:45,849 - Quant - INFO - Correcting layer layer1.1.conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:10:54,926 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:10:54,928 - Quant - INFO - Correcting layer layer1.1.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:11:03,853 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:11:03,855 - Quant - INFO - Correcting layer layer2.0.conv1 using Empirical Bias Correction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:11:14,173 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:11:14,175 - Quant - INFO - Correcting layer layer2.0.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:11:25,069 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:11:25,070 - Quant - INFO - Correcting layer layer2.0.downsample.0 using Empirical Bias Correction\n",
      "2023-01-06 16:11:36,092 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:11:36,094 - Quant - INFO - Correcting layer layer2.1.conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:11:48,811 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:11:48,812 - Quant - INFO - Correcting layer layer2.1.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:12:01,488 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:12:01,489 - Quant - INFO - Correcting layer layer3.0.conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:12:15,443 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:12:15,448 - Quant - INFO - Correcting layer layer3.0.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:12:30,455 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:12:30,457 - Quant - INFO - Correcting layer layer3.0.downsample.0 using Empirical Bias Correction\n",
      "2023-01-06 16:12:45,447 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:12:45,449 - Quant - INFO - Correcting layer layer3.1.conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:13:01,693 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:13:01,694 - Quant - INFO - Correcting layer layer3.1.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:13:18,403 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:13:18,404 - Quant - INFO - Correcting layer layer4.0.conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:13:36,795 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:13:36,798 - Quant - INFO - Correcting layer layer4.0.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:13:56,114 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:13:56,115 - Quant - INFO - Correcting layer layer4.0.downsample.0 using Empirical Bias Correction\n",
      "2023-01-06 16:14:15,547 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:14:15,549 - Quant - INFO - Correcting layer layer4.1.conv1 using Empirical Bias Correction\n",
      "2023-01-06 16:14:36,544 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:14:36,545 - Quant - INFO - Correcting layer layer4.1.conv2 using Empirical Bias Correction\n",
      "2023-01-06 16:14:59,556 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:14:59,557 - Quant - INFO - Correcting layer fc using Empirical Bias Correction\n",
      "2023-01-06 16:15:22,853 - Quant - INFO - Corrected bias for the layer\n",
      "2023-01-06 16:15:22,854 - Quant - INFO - Completed bias correction\n",
      "CPU times: user 9min 21s, sys: 3.48 s, total: 9min 25s\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "correct_bias(model, bc_params, num_quant_samples=500,\n",
    "             data_loader=train_loader, num_bias_correct_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f438234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:15:26,372 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-06 16:15:26,391 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-06 16:15:26,392 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-06 16:15:26,393 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-06 16:15:26,397 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 16:15:26,399 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-06 16:15:26,400 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 16:15:26,400 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-06 16:15:26,401 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 16:15:26,402 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2023-01-06 16:15:26,403 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 16:15:26,404 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2023-01-06 16:15:26,405 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 16:15:26,405 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2023-01-06 16:15:26,406 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 16:15:26,407 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2023-01-06 16:15:26,408 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 16:15:26,409 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-06 16:15:26,410 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 16:15:26,411 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2023-01-06 16:15:26,412 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 16:15:26,412 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2023-01-06 16:15:26,413 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 16:15:26,415 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2023-01-06 16:15:26,417 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 16:15:26,418 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2023-01-06 16:15:26,419 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 16:15:26,420 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2023-01-06 16:15:26,421 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 16:15:26,422 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2023-01-06 16:15:26,423 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 16:15:26,424 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2023-01-06 16:15:26,424 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 16:15:26,425 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2023-01-06 16:15:26,426 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 16:15:26,426 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2023-01-06 16:15:26,427 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2023-01-06 16:15:26,428 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)  \n",
    "dummy_input = dummy_input.to(device)\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=4,\n",
    "                           default_param_bw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a38698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43b71d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 157/157 [01:51<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.2384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy(sim.model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bb94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7958ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

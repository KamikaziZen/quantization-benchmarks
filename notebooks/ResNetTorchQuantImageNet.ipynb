{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fa6b53-eabf-4dd6-97eb-ad3f1f5355a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ded9b2-1ccc-409a-b3e7-5bbde4f10afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/tqdm-4.64.1-py3.9.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.quantization import MovingAverageMinMaxObserver,HistogramObserver\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from source.data import get_imagenet_test_loader, get_imagenet_train_val_loaders\n",
    "from source.models import ResNet18Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6de4fe5-8ee6-4954-add5-490a08781db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, dataset_loader, device='cuda', num_classes=1000):\n",
    "    def one_hot(x, K):\n",
    "        return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\n",
    "    \n",
    "    # Set BN and Droupout to eval regime\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "\n",
    "    for (x, y) in tqdm(dataset_loader):\n",
    "        x = x.to(device)\n",
    "        y = one_hot(np.array(y.numpy()), num_classes)\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(x).cpu().detach().numpy()\n",
    "            predicted_class = np.argmax(out, axis=1)\n",
    "            total_correct += np.sum(predicted_class == target_class)\n",
    "\n",
    "    total = len(dataset_loader) * dataset_loader.batch_size\n",
    "    return total_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cda4193-6d1e-4790-8fda-152ad4ced70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a52d8f1-a4aa-4b34-a7c0-42922cbb2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_imagenet_train_val_loaders(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/',\n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       val_perc=0.04,\n",
    "                                       shuffle=True,\n",
    "                                       random_seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042f4c20-e9ee-496f-a46f-b2d943485933",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_imagenet_test_loader(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/', \n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad12fb48-3608-47a5-aa49-64c79de0d4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# model = resnet18(pretrained=True)\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399fbc37-0e89-4300-8ab8-73e520417917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:34<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 s, sys: 8.14 s, total: 29.4 s\n",
      "Wall time: 2min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(model, test_loader, device='cuda', num_classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8fe0d-a7ed-4eba-a96d-91b2fdc0f6d1",
   "metadata": {},
   "source": [
    "## Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ab56e97-3fc0-41f0-8045-e13757d9b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88997cc9-adad-4932-8096-ff21bdea8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.quantization.quantize_dynamic(\n",
    "    model,\n",
    "    {torch.nn.Conv2d, torch.nn.Linear, torch.nn.BatchNorm2d,\n",
    "     torch.nn.ReLU, torch.nn.MaxPool2d, torch.nn.AdaptiveAvgPool2d},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "# model.qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5720f015-a9a8-4846-8497-ca0c47e6270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [21:07<00:00, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 15s, sys: 6min 42s, total: 46min 57s\n",
      "Wall time: 21min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6976"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(model, test_loader, device='cpu', num_classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8176892b-8fb0-4c53-b045-8ccfc0655d5b",
   "metadata": {},
   "source": [
    "## Static Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa3a4c3-ac3f-4d90-8774-e0fb9fadf590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18Quant(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicQuantBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicQuantBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicQuantBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicQuantBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicQuantBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicQuantBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicQuantBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): BasicQuantBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ff): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = ResNet18_Weights.verify(ResNet18_Weights.IMAGENET1K_V1)\n",
    "model = ResNet18Quant(num_classes=len(weights.meta[\"categories\"]))\n",
    "model.load_state_dict(weights.get_state_dict(progress=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442538f9-c5a3-4d82-9b1c-24ef53812f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_affine, dtype=torch.qint8){})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model.qconfig = torch.quantization.QConfig(\n",
    "  activation=HistogramObserver.with_args(reduce_range=True),\n",
    "  weight=MovingAverageMinMaxObserver.with_args(qscheme=torch.per_tensor_affine, dtype=torch.qint8)\n",
    ")\n",
    "model.qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec935eb-3c08-4a7c-b3e2-74425b3a0b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['conv1', 'bn1', 'relu'],\n",
       " ['layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu1'],\n",
       " ['layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu1'],\n",
       " ['layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu1'],\n",
       " ['layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu1'],\n",
       " ['layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu1'],\n",
       " ['layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu1'],\n",
       " ['layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu1'],\n",
       " ['layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu1'],\n",
       " ['layer1.0.conv2', 'layer1.0.bn2'],\n",
       " ['layer1.1.conv2', 'layer1.1.bn2'],\n",
       " ['layer2.0.conv2', 'layer2.0.bn2'],\n",
       " ['layer2.1.conv2', 'layer2.1.bn2'],\n",
       " ['layer3.0.conv2', 'layer3.0.bn2'],\n",
       " ['layer3.1.conv2', 'layer3.1.bn2'],\n",
       " ['layer4.0.conv2', 'layer4.0.bn2'],\n",
       " ['layer4.1.conv2', 'layer4.1.bn2'],\n",
       " ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
       " ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
       " ['layer4.0.downsample.0', 'layer4.0.downsample.1']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules_to_fuse = [\n",
    "    ['conv1', 'bn1', 'relu'],\n",
    "    *([f'layer{i}.{j}.conv1', f'layer{i}.{j}.bn1', f'layer{i}.{j}.relu1'] for i in (1,2,3,4) for j in (0,1)),\n",
    "    *([f'layer{i}.{j}.conv2', f'layer{i}.{j}.bn2'] for i in (1,2,3,4) for j in (0,1)),\n",
    "    *([f'layer{i}.0.downsample.0', f'layer{i}.0.downsample.1'] for i in (2,3,4))\n",
    "]\n",
    "modules_to_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd13785-80c2-4fbe-956c-2b577d6a444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.quantization.fuse_modules(model, modules_to_fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1aa883b-6ba4-44ab-b126-f6516b8f4455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torch/ao/quantization/observer.py:176: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = torch.quantization.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbe492b-40f4-4e8e-9b5a-ef0bd31d8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a8a504e-f05a-46f3-b72d-1363a088834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can move to gpu for faster quantization calbration\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44129c81-cf21-44a4-a0f9-7ed4416b8967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a60a106a-3ffe-4c7f-b9d9-8b9532173b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# quantiation calibration on 1000 samples of train dataset\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (train_x, _) in tqdm(enumerate(train_loader)):\n",
    "        _ = model(train_x.cuda())\n",
    "        if idx * train_loader.batch_size >= 1000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17167488-f94c-4117-a36d-7ca7fb2d2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to move to cpu for quantization conversion\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7b3e837-9777-40c4-9097-4cfa6c7b9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.quantization.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65333a5a-1edb-41bc-b9d4-3e68786c4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:27<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49min 45s, sys: 12.5 s, total: 49min 57s\n",
      "Wall time: 15min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(model, test_loader, device='cpu', num_classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fadb3d3-f7fa-450e-98f0-824ffde89f30",
   "metadata": {},
   "source": [
    "## Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba2e8e-47b6-4135-9805-1bc80bf775b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark23",
   "language": "python",
   "name": "mark23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

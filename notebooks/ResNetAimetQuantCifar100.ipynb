{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db071d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93434be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:54:03,824 - root - INFO - AIMET\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import ResNet\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from aimet_torch.model_preparer import prepare_model\n",
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "from aimet_torch.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "\n",
    "from source.data import get_training_dataloader, get_test_dataloader\n",
    "from source.models import BasicBlock, ResNet18Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b350721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, dataloader, device='gpu'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0.0\n",
    "        for (images, labels) in tqdm(dataloader):\n",
    "            if device == 'gpu':\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum()\n",
    "\n",
    "    print('Acc:', correct.float() / len(dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114b229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf112433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_training_dataloader(\n",
    "    '../data',\n",
    "    CIFAR100_TRAIN_MEAN,\n",
    "    CIFAR100_TRAIN_STD,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = get_test_dataloader(\n",
    "    '../data',\n",
    "    CIFAR100_TRAIN_MEAN,\n",
    "    CIFAR100_TRAIN_STD,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca763c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(sim_model, use_cuda):\n",
    "    batch_size = train_loader.batch_size\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    sim_model.eval()\n",
    "    samples = 1000\n",
    "\n",
    "    batch_cntr = 0\n",
    "    with torch.no_grad():\n",
    "        for input_data, target_data in train_loader:\n",
    "\n",
    "            inputs_batch = input_data.to(device)\n",
    "            sim_model(inputs_batch)\n",
    "\n",
    "            batch_cntr += 1\n",
    "            print(batch_cntr * batch_size)\n",
    "            if (batch_cntr * batch_size) > samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b94cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(num_classes=100, block=BasicBlock, layers=[2, 2, 2, 2])\n",
    "model.load_state_dict(torch.load('../models/resnet18_cifar100.sd'))\n",
    "model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f04234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:02<00:00, 136.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.5515, device='cuda:0')\n",
      "CPU times: user 1.41 s, sys: 276 ms, total: 1.69 s\n",
      "Wall time: 2.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(model, test_loader, device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8dc65",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89db89d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:53:18,450 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2022-12-21 23:53:18,450 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2022-12-21 23:53:18,451 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2022-12-21 23:53:18,452 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2022-12-21 23:53:18,452 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2022-12-21 23:53:18,453 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2022-12-21 23:53:18,453 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2022-12-21 23:53:18,454 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2022-12-21 23:53:18,454 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2022-12-21 23:53:18,455 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2022-12-21 23:53:18,455 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2022-12-21 23:53:18,456 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2022-12-21 23:53:18,457 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2022-12-21 23:53:18,457 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2022-12-21 23:53:18,458 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2022-12-21 23:53:18,458 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980bcea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:53:19,001 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2022-12-21 23:53:19,002 - Utils - INFO - ...... subset to store [Conv_4, BatchNormalization_5]\n",
      "2022-12-21 23:53:19,002 - Utils - INFO - ...... subset to store [Conv_7, BatchNormalization_8]\n",
      "2022-12-21 23:53:19,002 - Utils - INFO - ...... subset to store [Conv_11, BatchNormalization_12]\n",
      "2022-12-21 23:53:19,003 - Utils - INFO - ...... subset to store [Conv_14, BatchNormalization_15]\n",
      "2022-12-21 23:53:19,003 - Utils - INFO - ...... subset to store [Conv_18, BatchNormalization_19]\n",
      "2022-12-21 23:53:19,004 - Utils - INFO - ...... subset to store [Conv_21, BatchNormalization_22]\n",
      "2022-12-21 23:53:19,004 - Utils - INFO - ...... subset to store [Conv_27, BatchNormalization_28]\n",
      "2022-12-21 23:53:19,004 - Utils - INFO - ...... subset to store [Conv_30, BatchNormalization_31]\n",
      "2022-12-21 23:53:19,005 - Utils - INFO - ...... subset to store [Conv_34, BatchNormalization_35]\n",
      "2022-12-21 23:53:19,005 - Utils - INFO - ...... subset to store [Conv_37, BatchNormalization_38]\n",
      "2022-12-21 23:53:19,006 - Utils - INFO - ...... subset to store [Conv_43, BatchNormalization_44]\n",
      "2022-12-21 23:53:19,006 - Utils - INFO - ...... subset to store [Conv_46, BatchNormalization_47]\n",
      "2022-12-21 23:53:19,006 - Utils - INFO - ...... subset to store [Conv_50, BatchNormalization_51]\n",
      "2022-12-21 23:53:19,007 - Utils - INFO - ...... subset to store [Conv_53, BatchNormalization_54]\n",
      "2022-12-21 23:53:19,007 - Utils - INFO - ...... subset to store [Conv_59, BatchNormalization_60]\n",
      "2022-12-21 23:53:19,008 - Utils - INFO - ...... subset to store [Conv_62, BatchNormalization_63]\n",
      "2022-12-21 23:53:19,008 - Utils - INFO - ...... subset to store [Conv_55, BatchNormalization_56]\n",
      "2022-12-21 23:53:19,009 - Utils - INFO - ...... subset to store [Conv_39, BatchNormalization_40]\n",
      "2022-12-21 23:53:19,009 - Utils - INFO - ...... subset to store [Conv_23, BatchNormalization_24]\n"
     ]
    }
   ],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe3117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:53:22,829 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2022-12-21 23:53:22,849 - Quant - INFO - Unsupported op type Squeeze\n",
      "2022-12-21 23:53:22,849 - Quant - INFO - Unsupported op type Pad\n",
      "2022-12-21 23:53:22,849 - Quant - INFO - Unsupported op type Mean\n",
      "2022-12-21 23:53:22,852 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-21 23:53:22,853 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-21 23:53:22,853 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-21 23:53:22,854 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-21 23:53:22,854 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-21 23:53:22,855 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-21 23:53:22,855 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-21 23:53:22,855 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-21 23:53:22,856 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-21 23:53:22,856 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-21 23:53:22,857 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-21 23:53:22,857 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-21 23:53:22,857 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-21 23:53:22,858 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-21 23:53:22,858 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-21 23:53:22,859 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-21 23:53:22,859 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-21 23:53:22,859 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-21 23:53:22,860 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-21 23:53:22,860 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-21 23:53:22,861 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-21 23:53:22,861 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-21 23:53:22,861 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-21 23:53:22,862 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-21 23:53:22,862 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-21 23:53:22,863 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-21 23:53:22,863 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-21 23:53:22,864 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-21 23:53:22,864 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-21 23:53:22,864 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-21 23:53:22,865 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-21 23:53:22,865 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-21 23:53:22,866 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2022-12-21 23:53:22,866 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)    # Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=4,\n",
    "                           default_param_bw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92fa3590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04ceaf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 55.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.2235, device='cuda:0')\n",
      "CPU times: user 1.89 s, sys: 259 ms, total: 2.15 s\n",
      "Wall time: 2.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(sim.model, test_loader, device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3985f",
   "metadata": {},
   "source": [
    "# AdaRound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5e549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:54:11,038 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2022-12-21 23:54:11,039 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2022-12-21 23:54:11,039 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2022-12-21 23:54:11,041 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2022-12-21 23:54:11,042 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2022-12-21 23:54:11,042 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2022-12-21 23:54:11,044 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2022-12-21 23:54:11,045 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2022-12-21 23:54:11,045 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2022-12-21 23:54:11,046 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2022-12-21 23:54:11,046 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2022-12-21 23:54:11,047 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2022-12-21 23:54:11,048 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2022-12-21 23:54:11,048 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2022-12-21 23:54:11,049 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2022-12-21 23:54:11,049 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589abdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:54:11,940 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2022-12-21 23:54:11,940 - Utils - INFO - ...... subset to store [Conv_4, BatchNormalization_5]\n",
      "2022-12-21 23:54:11,941 - Utils - INFO - ...... subset to store [Conv_7, BatchNormalization_8]\n",
      "2022-12-21 23:54:11,941 - Utils - INFO - ...... subset to store [Conv_11, BatchNormalization_12]\n",
      "2022-12-21 23:54:11,942 - Utils - INFO - ...... subset to store [Conv_14, BatchNormalization_15]\n",
      "2022-12-21 23:54:11,942 - Utils - INFO - ...... subset to store [Conv_18, BatchNormalization_19]\n",
      "2022-12-21 23:54:11,943 - Utils - INFO - ...... subset to store [Conv_21, BatchNormalization_22]\n",
      "2022-12-21 23:54:11,943 - Utils - INFO - ...... subset to store [Conv_27, BatchNormalization_28]\n",
      "2022-12-21 23:54:11,943 - Utils - INFO - ...... subset to store [Conv_30, BatchNormalization_31]\n",
      "2022-12-21 23:54:11,944 - Utils - INFO - ...... subset to store [Conv_34, BatchNormalization_35]\n",
      "2022-12-21 23:54:11,944 - Utils - INFO - ...... subset to store [Conv_37, BatchNormalization_38]\n",
      "2022-12-21 23:54:11,945 - Utils - INFO - ...... subset to store [Conv_43, BatchNormalization_44]\n",
      "2022-12-21 23:54:11,945 - Utils - INFO - ...... subset to store [Conv_46, BatchNormalization_47]\n",
      "2022-12-21 23:54:11,945 - Utils - INFO - ...... subset to store [Conv_50, BatchNormalization_51]\n",
      "2022-12-21 23:54:11,946 - Utils - INFO - ...... subset to store [Conv_53, BatchNormalization_54]\n",
      "2022-12-21 23:54:11,946 - Utils - INFO - ...... subset to store [Conv_59, BatchNormalization_60]\n",
      "2022-12-21 23:54:11,947 - Utils - INFO - ...... subset to store [Conv_62, BatchNormalization_63]\n",
      "2022-12-21 23:54:11,947 - Utils - INFO - ...... subset to store [Conv_55, BatchNormalization_56]\n",
      "2022-12-21 23:54:11,948 - Utils - INFO - ...... subset to store [Conv_39, BatchNormalization_40]\n",
      "2022-12-21 23:54:11,948 - Utils - INFO - ...... subset to store [Conv_23, BatchNormalization_24]\n"
     ]
    }
   ],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd20314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AdaroundParameters(data_loader=train_loader, num_batches=2000//train_loader.batch_size, default_num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9b009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72bec81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./cifar100_w4/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21111453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n",
      "2022-12-21 23:54:16,410 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2022-12-21 23:54:16,429 - Quant - INFO - Unsupported op type Squeeze\n",
      "2022-12-21 23:54:16,429 - Quant - INFO - Unsupported op type Pad\n",
      "2022-12-21 23:54:16,429 - Quant - INFO - Unsupported op type Mean\n",
      "2022-12-21 23:54:16,432 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-21 23:54:16,433 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-21 23:54:16,433 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-21 23:54:16,434 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-21 23:54:16,434 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-21 23:54:16,435 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-21 23:54:16,435 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-21 23:54:16,435 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-21 23:54:16,436 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-21 23:54:16,436 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-21 23:54:16,437 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-21 23:54:16,437 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-21 23:54:16,437 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-21 23:54:16,438 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-21 23:54:16,438 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-21 23:54:16,438 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-21 23:54:16,439 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-21 23:54:16,439 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-21 23:54:16,440 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-21 23:54:16,440 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-21 23:54:16,441 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-21 23:54:16,441 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-21 23:54:16,441 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-21 23:54:16,442 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-21 23:54:16,442 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-21 23:54:16,443 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-21 23:54:16,443 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-21 23:54:16,443 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-21 23:54:16,444 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-21 23:54:16,444 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-21 23:54:16,445 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-21 23:54:16,445 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-21 23:54:16,446 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2022-12-21 23:54:16,446 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2022-12-21 23:54:17,997 - Utils - INFO - Caching 31 batches from data loader at path location: /tmp/adaround/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:54:18,098 - Quant - INFO - Started Optimizing weight rounding of module: conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:54:34,695 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:54:53,694 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:55:12,395 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:55:31,481 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:55:50,205 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:56:11,502 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:56:30,401 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:56:48,925 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:57:08,328 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:57:27,315 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:57:48,586 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:58:07,823 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:58:26,842 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:58:46,560 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:59:05,891 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:59:24,179 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-21 23:59:50,407 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:00:08,270 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:00:34,791 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:01:01,422 - Quant - INFO - Started Optimizing weight rounding of module: fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [06:58<00:00,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:01:16,722 - Quant - INFO - Deleting model inputs from location: /tmp/adaround/\n",
      "2022-12-22 00:01:16,782 - Quant - INFO - Completed Adarounding Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "ada_model = Adaround.apply_adaround(model, dummy_input, params,\n",
    "                                    path=\"cifar100_w4\", \n",
    "                                    filename_prefix='adaround', \n",
    "                                    default_param_bw=4,\n",
    "                                    default_quant_scheme=QuantScheme.post_training_tf_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8d3d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:01:17,018 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2022-12-22 00:01:17,035 - Quant - INFO - Unsupported op type Squeeze\n",
      "2022-12-22 00:01:17,036 - Quant - INFO - Unsupported op type Pad\n",
      "2022-12-22 00:01:17,036 - Quant - INFO - Unsupported op type Mean\n",
      "2022-12-22 00:01:17,039 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-22 00:01:17,040 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2022-12-22 00:01:17,040 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-22 00:01:17,041 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2022-12-22 00:01:17,041 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-22 00:01:17,042 - Utils - INFO - ...... subset to store [Add_6, Relu_7]\n",
      "2022-12-22 00:01:17,042 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-22 00:01:17,042 - Utils - INFO - ...... subset to store [Conv_8, Relu_9]\n",
      "2022-12-22 00:01:17,043 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-22 00:01:17,043 - Utils - INFO - ...... subset to store [Add_11, Relu_12]\n",
      "2022-12-22 00:01:17,044 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-22 00:01:17,044 - Utils - INFO - ...... subset to store [Conv_13, Relu_14]\n",
      "2022-12-22 00:01:17,044 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-22 00:01:17,045 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2022-12-22 00:01:17,045 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-22 00:01:17,046 - Utils - INFO - ...... subset to store [Conv_19, Relu_20]\n",
      "2022-12-22 00:01:17,046 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-22 00:01:17,046 - Utils - INFO - ...... subset to store [Add_22, Relu_23]\n",
      "2022-12-22 00:01:17,047 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-22 00:01:17,047 - Utils - INFO - ...... subset to store [Conv_24, Relu_25]\n",
      "2022-12-22 00:01:17,048 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-22 00:01:17,048 - Utils - INFO - ...... subset to store [Add_28, Relu_29]\n",
      "2022-12-22 00:01:17,049 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-22 00:01:17,049 - Utils - INFO - ...... subset to store [Conv_30, Relu_31]\n",
      "2022-12-22 00:01:17,049 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-22 00:01:17,050 - Utils - INFO - ...... subset to store [Add_33, Relu_34]\n",
      "2022-12-22 00:01:17,050 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-22 00:01:17,051 - Utils - INFO - ...... subset to store [Conv_35, Relu_36]\n",
      "2022-12-22 00:01:17,051 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-22 00:01:17,051 - Utils - INFO - ...... subset to store [Add_39, Relu_40]\n",
      "2022-12-22 00:01:17,052 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-22 00:01:17,052 - Utils - INFO - ...... subset to store [Conv_41, Relu_42]\n",
      "2022-12-22 00:01:17,053 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n",
      "2022-12-22 00:01:17,053 - Utils - INFO - ...... subset to store [Add_44, Relu_45]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)    # Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=ada_model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=4,\n",
    "                           default_param_bw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa25e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22 00:01:17,181 - Quant - INFO - Setting quantization encodings for parameter: conv1.weight\n",
      "2022-12-22 00:01:17,181 - Quant - INFO - Freezing quantization encodings for parameter: conv1.weight\n",
      "2022-12-22 00:01:17,182 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.weight\n",
      "2022-12-22 00:01:17,182 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.weight\n",
      "2022-12-22 00:01:17,183 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.weight\n",
      "2022-12-22 00:01:17,183 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.weight\n",
      "2022-12-22 00:01:17,184 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.weight\n",
      "2022-12-22 00:01:17,184 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.weight\n",
      "2022-12-22 00:01:17,184 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.weight\n",
      "2022-12-22 00:01:17,185 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.weight\n",
      "2022-12-22 00:01:17,185 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.weight\n",
      "2022-12-22 00:01:17,186 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.weight\n",
      "2022-12-22 00:01:17,186 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.weight\n",
      "2022-12-22 00:01:17,186 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.weight\n",
      "2022-12-22 00:01:17,187 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,187 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,188 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.weight\n",
      "2022-12-22 00:01:17,188 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.weight\n",
      "2022-12-22 00:01:17,188 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.weight\n",
      "2022-12-22 00:01:17,189 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.weight\n",
      "2022-12-22 00:01:17,189 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.weight\n",
      "2022-12-22 00:01:17,190 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.weight\n",
      "2022-12-22 00:01:17,190 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.weight\n",
      "2022-12-22 00:01:17,190 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.weight\n",
      "2022-12-22 00:01:17,191 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,191 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,192 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.weight\n",
      "2022-12-22 00:01:17,192 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.weight\n",
      "2022-12-22 00:01:17,193 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.weight\n",
      "2022-12-22 00:01:17,193 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.weight\n",
      "2022-12-22 00:01:17,193 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.weight\n",
      "2022-12-22 00:01:17,194 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.weight\n",
      "2022-12-22 00:01:17,194 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.weight\n",
      "2022-12-22 00:01:17,195 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.weight\n",
      "2022-12-22 00:01:17,195 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,195 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2022-12-22 00:01:17,196 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.weight\n",
      "2022-12-22 00:01:17,196 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.weight\n",
      "2022-12-22 00:01:17,197 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.weight\n",
      "2022-12-22 00:01:17,197 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.weight\n",
      "2022-12-22 00:01:17,197 - Quant - INFO - Setting quantization encodings for parameter: fc.weight\n",
      "2022-12-22 00:01:17,198 - Quant - INFO - Freezing quantization encodings for parameter: fc.weight\n"
     ]
    }
   ],
   "source": [
    "sim.set_and_freeze_param_encodings(encoding_path=os.path.join(\"cifar100_w4\", 'adaround.encodings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a06e320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d21d6df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 56.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: tensor(0.4052, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "accuracy(sim.model, test_loader, device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f4edb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 21 23:23:02 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:1E:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    39W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0e1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
